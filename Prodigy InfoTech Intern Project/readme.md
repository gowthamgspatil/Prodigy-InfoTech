#  Prodigy InfoTech Internship Projects

**Domain: Data Science & Machine Learning**

This repository contains my internship tasks completed as part of the **Prodigy InfoTech Data Science Internship**.
Each task involves applying **data analysis, machine learning, and visualization techniques** on real-world datasets.

---

##  Repository Structure

```
Prodigy InfoTech Intern Project/
│── Task 1 - [File(s) & Notebook]
│── Task 2 - [File(s) & Notebook]
│── Task 3 - Decision Tree Classifier
│   ├── bank-additional.csv
│   ├── Decision_tree.ipynb
│── Task 4 - Sentiment Analysis / US Accidents
│   ├── twitter_training.csv (or Kaggle US Accidents dataset)
│   ├── Sentiment_Analysis.ipynb / us-accident.ipynb
│── README.md
```

---

##  Tasks Overview

###  Task 1 – \[Brief Name of Task]

* **Objective:** \[Explain what Task 1 was about – e.g., Data Cleaning / EDA / Visualization]
* **Files:** `Task1.ipynb`, dataset file (if used)
* **Key Steps:** Data preprocessing, visualization, and insight generation.
* **Outcome:** \[Summarize result briefly].

---

###  Task 2 – \[Brief Name of Task]

* **Objective:** \[Explain what Task 2 was about – e.g., Regression / Classification / Clustering]
* **Files:** `Task2.ipynb`, dataset file (if used)
* **Key Steps:** Model building, training, and evaluation.
* **Outcome:** \[Summarize result briefly].

---

###  Task 3 – Decision Tree Classifier

* **Objective:** Implement a **Decision Tree Classifier** to predict whether a client subscribes to a term deposit.
* **Files:**

  * `bank-additional.csv` → Bank Marketing dataset
  * `Decision_tree.ipynb` → Model implementation
* **Key Steps:**

  1. Data preprocessing (handling categorical variables)
  2. Splitting into train/test sets
  3. Building a Decision Tree model
  4. Evaluating with accuracy, confusion matrix, and classification report
  5. Visualizing the decision tree
* **Outcome:** Achieved predictions on customer subscription with interpretable decision rules.

---

###  Task 4 – Sentiment Analysis / US Accidents EDA

* **Objective:**

  * **Option 1:** Perform **Sentiment Analysis** on Twitter dataset (`twitter_training.csv`).
  * **Option 2:** Perform **Exploratory Data Analysis** on the **US Accidents Dataset** from Kaggle.
* **Files:**

  * `twitter_training.csv` / Kaggle Dataset
  * `Sentiment_Analysis.ipynb` / `us-accident.ipynb`
* **Key Steps:**

  1. Data cleaning & preprocessing (text cleaning for sentiment OR missing value handling for accidents)
  2. Feature engineering
  3. Model building (Logistic Regression / Naive Bayes for sentiment) OR Visualization (accident trends, maps, severity analysis)
  4. Evaluation with accuracy and classification report (for sentiment)
* **Outcome:**

  * Built a sentiment classifier with measurable accuracy
  * OR extracted accident trends across US states with visual insights

---

##  Requirements

Install the following libraries before running any notebook:

```bash
pip install pandas numpy matplotlib seaborn scikit-learn nltk plotly
```

---

##  How to Run

1. Clone this repository:

   ```bash
   git clone https://github.com/gowthamgspatil/Prodigy-InfoTech.git
   cd Prodigy-InfoTech/Prodigy InfoTech Intern Project
   ```
2. Open Jupyter Notebook:

   ```bash
   jupyter notebook
   ```
3. Run each task notebook sequentially.

---

##  Internship Info

This repository contains all projects completed for the **Prodigy InfoTech Data Science Internship Program**.
Each task demonstrates skills in **data analysis, machine learning, NLP, and visualization**.

---

##  Contact

For queries, collaborations, or feedback, feel free to connect with me:

* **LinkedIn:** [Your LinkedIn Profile](https://linkedin.com/in/yourprofile)
* **Gmail:** [your.email@gmail.com](mailto:your.email@gmail.com)

---
